{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qw30Vm0vAQYe","executionInfo":{"status":"ok","timestamp":1715000991779,"user_tz":-540,"elapsed":45924,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"37ddc50a-9ab3-4862-c9fa-4de101d0f16e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/deep-voice/data\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import warnings\n","import tensorflow as tf\n","from tqdm import tqdm\n","from glob import glob\n","from google.colab import drive\n","\n","import librosa\n","import librosa.display as dsp\n","import IPython.display as ipd\n","\n","warnings.filterwarnings(action='ignore')\n","drive.mount('/content/drive')\n","\n","%cd '/content/drive/MyDrive/deep-voice/data/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kb9i7qDEAQqE"},"outputs":[],"source":["import torch\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') #GPU 할당"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715000991779,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"vwbYsyOKAScP"},"outputs":[],"source":["import random\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything(813)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":37011,"status":"ok","timestamp":1715001028788,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"VnJQgiuDAUPm"},"outputs":[],"source":["# 저장된 데이터 불러오기\n","X_train_mel = np.load('X_train_mel.npy')\n","X_test_mel = np.load('X_test_mel.npy')\n","X_val_mel = np.load('X_val_mel.npy')\n","\n","y_train = np.load('y_train.npy')\n","y_test = np.load('y_test.npy')\n","y_val = np.load('y_val.npy')"]},{"cell_type":"markdown","metadata":{"id":"8TMy0N-k1r99"},"source":["## VGG19"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2462,"status":"ok","timestamp":1715001045969,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"xcPIozZ8AkdS","outputId":"f435b553-cb69-486e-b846-1136debc5bf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lambda (Lambda)             (None, 128, 256, 3)       0         \n","                                                                 \n"," vgg19 (Functional)          (None, 4, 8, 512)         20024384  \n","                                                                 \n"," flatten (Flatten)           (None, 16384)             0         \n","                                                                 \n"," dropout (Dropout)           (None, 16384)             0         \n","                                                                 \n"," dense (Dense)               (None, 512)               8389120   \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 28414017 (108.39 MB)\n","Trainable params: 8389633 (32.00 MB)\n","Non-trainable params: 20024384 (76.39 MB)\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Lambda, Flatten, Dropout, Dense\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l1_l2  # L1, L2 정규화를 위한 라이브러리\n","\n","input_shape = X_train_mel.shape[1:]  # X_train_mel은 사용자의 데이터로 가정\n","\n","# 데이터 전처리를 동적으로 처리하는 Lambda 레이어 함수\n","def dynamic_preprocess(x):\n","    # 이미지 크기를 (128, 512)으로 조정\n","    x = tf.image.resize(x, [128, 256])\n","    return x\n","\n","vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(128, 256, 3))\n","# VGG19의 모든 계층을 동결합니다.\n","for layer in vgg19.layers:\n","    layer.trainable = False\n","\n","# Sequential 모델 구성\n","model = Sequential([\n","    Lambda(dynamic_preprocess, input_shape=(128, 256, 3)),  # 입력 데이터 차원 및 크기 조정\n","    vgg19,\n","    Flatten(),\n","    Dropout(0.5),  # 드롭아웃을 적용하여 일부 뉴런을 임의로 비활성화\n","    # L1, L2 정규화를 적용한 Dense 레이어\n","    Dense(512, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n","    Dense(1, activation='sigmoid')  # 최종 출력 계층을 이진 분류에 맞게 조정\n","])\n","\n","# 모델 컴파일\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 모델 요약\n","model.summary()"]},{"cell_type":"code","source":["import numpy as np\n","\n","def resize_and_duplicate_channel(data):\n","    # 데이터의 앞쪽 128 프레임만 사용하고, 마지막 차원에 대해 3회 복제\n","    resized_data = data[:, :, :256, np.newaxis]\n","    duplicated_data = np.repeat(resized_data, 3, axis=3)\n","    return duplicated_data\n","\n","X_train_mel_resized = resize_and_duplicate_channel(X_train_mel)\n","X_val_mel_resized = resize_and_duplicate_channel(X_val_mel)\n","X_test_mel_resized = resize_and_duplicate_channel(X_test_mel)"],"metadata":{"id":"x7up4j8e7ep_","executionInfo":{"status":"ok","timestamp":1715001047374,"user_tz":-540,"elapsed":1029,"user":{"displayName":"김민정","userId":"02244240816509024948"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["X_train_mel_resized.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-Pw5I5WgSLZ","executionInfo":{"status":"ok","timestamp":1715001047374,"user_tz":-540,"elapsed":2,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"bd4a5e52-aa0f-4e50-8118-1298020c7500"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(960, 128, 256, 3)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# ModelCheckpoint 설정\n","model_checkpoint = ModelCheckpoint(\n","    'best_model_vgg.h5', # 모델을 저장할 파일 이름\n","    monitor='val_accuracy', # 모니터링할 대상 ('val_loss'로 설정할 수도 있음)\n","    mode='max', # 'max'는 정확도를 모니터링할 때, 'min'은 손실을 모니터링할 때 사용\n","    save_best_only=True # True로 설정하면, 가장 좋은 성능을 보인 모델만 저장\n",")\n","\n","# EarlyStopping 콜백 설정\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n","\n","# 모델 학습\n","history = model.fit(\n","    X_train_mel_resized,\n","    y_train,\n","    epochs=10,\n","    validation_data=(X_val_mel_resized, y_val),\n","    callbacks=[early_stopping, model_checkpoint] # 콜백 추가\n",")"],"metadata":{"id":"HdAnJisw8hmk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"91545fab-0090-420f-fcff-3d424a0f2dd2","executionInfo":{"status":"ok","timestamp":1715007915858,"user_tz":-540,"elapsed":6865765,"user":{"displayName":"김민정","userId":"02244240816509024948"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","30/30 [==============================] - 682s 23s/step - loss: 695.0236 - accuracy: 0.9458 - val_loss: 585.0825 - val_accuracy: 1.0000\n","Epoch 2/10\n","30/30 [==============================] - 709s 24s/step - loss: 492.0841 - accuracy: 0.9979 - val_loss: 398.5992 - val_accuracy: 1.0000\n","Epoch 3/10\n","30/30 [==============================] - 710s 24s/step - loss: 322.7713 - accuracy: 0.9979 - val_loss: 248.0730 - val_accuracy: 1.0000\n","Epoch 4/10\n","30/30 [==============================] - 682s 23s/step - loss: 190.1919 - accuracy: 0.9990 - val_loss: 134.7675 - val_accuracy: 1.0000\n","Epoch 5/10\n","30/30 [==============================] - 679s 23s/step - loss: 95.0309 - accuracy: 0.9990 - val_loss: 58.9810 - val_accuracy: 1.0000\n","Epoch 6/10\n","30/30 [==============================] - 671s 23s/step - loss: 37.3297 - accuracy: 0.9990 - val_loss: 20.6104 - val_accuracy: 1.0000\n","Epoch 7/10\n","30/30 [==============================] - 678s 23s/step - loss: 15.0767 - accuracy: 0.9990 - val_loss: 11.1116 - val_accuracy: 1.0000\n","Epoch 8/10\n","30/30 [==============================] - 669s 22s/step - loss: 9.0554 - accuracy: 1.0000 - val_loss: 7.3136 - val_accuracy: 1.0000\n","Epoch 9/10\n","30/30 [==============================] - 716s 24s/step - loss: 6.2244 - accuracy: 1.0000 - val_loss: 5.2315 - val_accuracy: 1.0000\n","Epoch 10/10\n","30/30 [==============================] - 662s 22s/step - loss: 4.5557 - accuracy: 1.0000 - val_loss: 3.9236 - val_accuracy: 1.0000\n"]}]},{"cell_type":"code","source":["# 모델 불러오기\n","from tensorflow.keras.models import load_model\n","best_model = load_model('best_model_vgg.h5')\n","\n","# 불러온 모델로 테스트 데이터셋 성능 평가\n","test_loss, test_acc = best_model.evaluate(X_test_mel_resized, y_test)\n","print(f'\\nTest accuracy: {test_acc}, Test loss: {test_loss}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vty_1IIR7xYQ","executionInfo":{"status":"ok","timestamp":1715008132446,"user_tz":-540,"elapsed":206851,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"28c54871-956e-452e-9e78-23e566421281"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["10/10 [==============================] - 166s 17s/step - loss: 585.0825 - accuracy: 1.0000\n","\n","Test accuracy: 1.0, Test loss: 585.0824584960938\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hf_oEcBuxcqh"},"outputs":[],"source":["# from tensorflow.keras.callbacks import EarlyStopping\n","\n","# # EarlyStopping 콜백 설정\n","# early_stopping = EarlyStopping(\n","#     monitor='val_loss',  # 모니터링할 데이터\n","#     patience=10,         # 성능 향상이 없는 에폭을 몇 번이나 허용할 것인가\n","#     verbose=1,           # Early stopping의 진행 상황을 어떻게 표시할 것인지\n","#     restore_best_weights=True  # 가장 좋은 모델의 가중치를 복원할지 여부\n","# )\n","\n","# # 모델 훈련\n","# history = model.fit(\n","#     X_train_mel_resized, y_train,\n","#     epochs=10,\n","#     batch_size=32,\n","#     validation_data=(X_val_mel_resized, y_val),\n","#     callbacks=[early_stopping]  # 콜백 리스트에 early_stopping 추가\n","# )"]},{"cell_type":"code","source":["import numpy as np\n","import librosa\n","from tensorflow.keras.preprocessing import image\n","\n","def load_audio_file(file_path, sr=16000):\n","    # 오디오 파일을 로드하고 리샘플링\n","    audio, _ = librosa.load(file_path, sr=sr)\n","    return audio\n","\n","def extract_melspectrogram(audio, sr=16000, n_mels=128, hop_length=160, n_fft=400):\n","    # librosa.feature.melspectrogram 함수를 사용하여 Mel-Spectrogram 계산\n","    melspec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, hop_length=hop_length, n_fft=n_fft)\n","    melspec = librosa.power_to_db(melspec, ref=np.max)  # 데시벨 스케일로 변환\n","    return melspec\n","\n","def preprocess_melspectrogram(melspec, target_size=(128, 128)):\n","    # Mel-Spectrogram을 이미지로 변환\n","    melspec = np.stack((melspec,)*3, axis=-1)  # 3채널 이미지로 변환\n","    melspec = image.array_to_img(melspec)\n","    melspec = melspec.resize(target_size)\n","    melspec = image.img_to_array(melspec)\n","    melspec = np.expand_dims(melspec, axis=0)  # 배치 차원 추가\n","    return melspec\n","\n","# 오디오 파일 로드\n","audio_data = load_audio_file('/content/U00005.wav')\n","\n","# Mel-Spectrogram 추출\n","melspec = extract_melspectrogram(audio_data)\n","\n","# Mel-Spectrogram 전처리\n","melspec_processed = preprocess_melspectrogram(melspec)\n","\n","# 모델 예측\n","predictions = model.predict(melspec_processed)\n","predictions = predictions > 0.5  # 0.5를 기준으로 이진 분류\n","\n","# 결과 출력\n","if predictions[0] > 0.5:\n","    print(\"딥보이스\")\n","else:\n","    print(\"아님\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMkqSzxrT5NU","executionInfo":{"status":"ok","timestamp":1714907467359,"user_tz":-540,"elapsed":690,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"eef912fd-851f-4b1e-bbe6-b40c1742fc6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 313ms/step\n","아님\n"]}]},{"cell_type":"markdown","metadata":{"id":"DA-FWV0Z1upE"},"source":["## GoogleNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7373,"status":"ok","timestamp":1714633936582,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"rv6E8Ftq1uMj","outputId":"66e75092-aae0-4af5-d793-c69fcdc16010"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:00<00:00, 78.2MB/s]\n"]},{"data":{"text/plain":["GoogLeNet(\n","  (conv1): BasicConv2d(\n","    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (conv2): BasicConv2d(\n","    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (conv3): BasicConv2d(\n","    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception3a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception3b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception4a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4c): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4d): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4e): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception5a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception5b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (aux1): None\n","  (aux2): None\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torchvision import transforms, models\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import ToPILImage\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","from torchvision.transforms import ToTensor\n","\n","class CustomMelSpectrogramDataset(Dataset):\n","    def __init__(self, X_data, y_data, transform=None):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        mel_spec = self.X_data[idx]\n","\n","        # 이미 데이터가 (Height, Width) 형태라고 가정할 때,\n","        # 여기서는 데이터가 torch.Tensor 형태임을 확인\n","        if not isinstance(mel_spec, torch.Tensor):\n","            raise ValueError(f\"Expected torch.Tensor, got {type(mel_spec)}.\")\n","\n","        # (높이, 너비, 채널)에서 (채널, 높이, 너비)로 차원 재배열\n","        mel_spec = mel_spec.permute(2, 0, 1)\n","\n","        # 멜 스펙트로그램을 PIL 이미지로 변환 시도\n","        try:\n","            mel_spec_image = ToPILImage()(mel_spec)\n","        except ValueError as e:\n","            # 에러 핸들링\n","            print(f\"Error converting mel spectrogram to image: {e}\")\n","            # 에러 발생 시 특정 처리 로직 (예: 기본 이미지 할당)\n","            mel_spec_image = None  # or some default handling\n","\n","        # 추가 변형이 있으면 적용\n","        if self.transform:\n","            mel_spec_image = self.transform(mel_spec_image)\n","\n","        label = self.y_data[idx]\n","        return mel_spec_image, label\n","\n","    def __len__(self):\n","        # 데이터셋 내 아이템의 총 개수 반환\n","        return len(self.X_data)\n","\n","# 멜스펙트로그램 데이터를 텐서로 변환\n","X_train_mel_tensor = torch.tensor(X_train_mel, dtype=torch.float32)\n","X_val_mel_tensor = torch.tensor(X_val_mel, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n","\n","# 입력 데이터의 차원 변환 및 채널 조정을 위한 전처리 파이프라인\n","# 데이터의 크기를 (224, 224)로 조정하고, 1채널을 3채널로 복제\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조정\n","    transforms.Grayscale(num_output_channels=3), # 1채널을 3채널로 변경\n","    transforms.ToTensor()\n","])\n","\n","# 데이터셋 생성\n","train_dataset = CustomMelSpectrogramDataset(X_train_mel_tensor, y_train_tensor, transform=transform)\n","val_dataset = CustomMelSpectrogramDataset(X_val_mel_tensor, y_val_tensor, transform=transform)\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# GoogLeNet 모델 로드\n","model = models.googlenet(pretrained=True)\n","\n","# 마지막 FC 레이어를 사용자 정의 데이터셋에 맞게 변경\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 10)\n","\n","# 손실 함수 및 옵티마이저 설정\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# GPU 사용 가능 여부 확인 후 모델을 GPU로 전송\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1714466294404,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"9__4EYp44ezg","outputId":"b618c27c-a336-44fb-95bc-5392bf7a5825"},"outputs":[{"name":"stdout","output_type":"stream","text":["배치 인덱스: 0\n","데이터 형태: torch.Size([32, 3, 224, 224])\n","타겟 형태: torch.Size([32])\n"]}],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# DataLoader에서 첫 번째 배치의 형태를 출력합니다.\n","for batch_idx, (data, target) in enumerate(train_loader):\n","    print(f'배치 인덱스: {batch_idx}')\n","    print(f'데이터 형태: {data.shape}')  # 예: torch.Size([32, 10])\n","    print(f'타겟 형태: {target.shape}')  # 예: torch.Size([32])\n","    break  # 첫 번째 배치만 출력되도록 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BrgI0nS2kd-","outputId":"9fc4d584-380c-4371-b373-f59a57143190"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Epoch 1] loss: 31.059\n","[Epoch 1] val_loss: 3.336, Accuracy: 96.88 %\n","[Epoch 2] loss: 4.425\n","[Epoch 2] val_loss: 0.479, Accuracy: 99.38 %\n","Validation loss decreased (inf --> 0.479194).  Saving model ...\n","[Epoch 3] loss: 1.880\n","[Epoch 3] val_loss: 0.322, Accuracy: 99.38 %\n","Validation loss decreased (0.479194 --> 0.321925).  Saving model ...\n","[Epoch 4] loss: 1.297\n","[Epoch 4] val_loss: 0.203, Accuracy: 99.69 %\n","Validation loss decreased (0.321925 --> 0.203315).  Saving model ...\n","[Epoch 5] loss: 0.771\n","[Epoch 5] val_loss: 0.161, Accuracy: 99.69 %\n","Validation loss decreased (0.203315 --> 0.161418).  Saving model ...\n","[Epoch 6] loss: 0.941\n","[Epoch 6] val_loss: 0.134, Accuracy: 100.00 %\n","Validation loss decreased (0.161418 --> 0.133798).  Saving model ...\n","[Epoch 7] loss: 0.553\n","[Epoch 7] val_loss: 0.122, Accuracy: 100.00 %\n","Validation loss decreased (0.133798 --> 0.122250).  Saving model ...\n","[Epoch 8] loss: 0.399\n","[Epoch 8] val_loss: 0.110, Accuracy: 99.69 %\n","Validation loss decreased (0.122250 --> 0.109535).  Saving model ...\n","[Epoch 9] loss: 0.810\n","[Epoch 9] val_loss: 0.098, Accuracy: 99.69 %\n","Validation loss decreased (0.109535 --> 0.098390).  Saving model ...\n","[Epoch 10] loss: 0.418\n","[Epoch 10] val_loss: 0.078, Accuracy: 99.69 %\n","Validation loss decreased (0.098390 --> 0.078433).  Saving model ...\n","[Epoch 11] loss: 0.434\n","[Epoch 11] val_loss: 0.093, Accuracy: 99.69 %\n","EarlyStopping counter: 1 out of 20\n","[Epoch 12] loss: 0.342\n","[Epoch 12] val_loss: 0.073, Accuracy: 100.00 %\n","Validation loss decreased (0.078433 --> 0.073079).  Saving model ...\n","[Epoch 13] loss: 0.222\n","[Epoch 13] val_loss: 0.061, Accuracy: 100.00 %\n","Validation loss decreased (0.073079 --> 0.060691).  Saving model ...\n","[Epoch 14] loss: 0.193\n","[Epoch 14] val_loss: 0.060, Accuracy: 99.69 %\n","Validation loss decreased (0.060691 --> 0.060082).  Saving model ...\n","[Epoch 15] loss: 0.167\n"]}],"source":["import numpy as np\n","\n","class EarlyStopping:\n","    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 종료\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Arguments:\n","            patience (int): 개선된 validation loss가 관찰되지 않는 epoch 횟수 후에 학습을 중단할 횟수\n","            verbose (bool): 조기 종료 메시지를 출력할지 결정\n","            delta (float): 개선으로 간주되기 위한 최소 변화량\n","            path (str): 모델 저장 경로\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_loss = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss > self.best_loss + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            if val_loss < self.best_loss:\n","                self.save_checkpoint(val_loss, model)\n","                self.best_loss = val_loss\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''validation loss가 감소하면 모델을 저장합니다.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss\n","\n","# EarlyStopping 객체 초기화\n","early_stopping = EarlyStopping(patience=20, verbose=True)\n","\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print('[Epoch %d] loss: %.3f' % (epoch + 1, running_loss))\n","\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_accuracy = 100 * correct / total\n","    print('[Epoch %d] val_loss: %.3f, Accuracy: %.2f %%' % (epoch + 1, val_loss, val_accuracy))\n","\n","    early_stopping(val_loss, model)\n","    if early_stopping.early_stop:\n","        print(\"조기 종료\")\n","        break"]},{"cell_type":"markdown","metadata":{"id":"o1IbJu0Gq5nP"},"source":["## ResNet18"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4636,"status":"ok","timestamp":1714582970752,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"G6j06OvLq7Te","outputId":"3730acb8-699d-4612-8b37-68940ce9327e"},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torchvision import transforms, models\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import ToPILImage\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","from torchvision.transforms import ToTensor\n","\n","class CustomMelSpectrogramDataset(Dataset):\n","    def __init__(self, X_data, y_data, transform=None):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        mel_spec = self.X_data[idx]\n","\n","        # 이미 데이터가 (Height, Width) 형태라고 가정할 때,\n","        # 여기서는 데이터가 torch.Tensor 형태임을 확인\n","        if not isinstance(mel_spec, torch.Tensor):\n","            raise ValueError(f\"Expected torch.Tensor, got {type(mel_spec)}.\")\n","\n","        # (높이, 너비, 채널)에서 (채널, 높이, 너비)로 차원 재배열\n","        mel_spec = mel_spec.permute(2, 0, 1)\n","\n","        # 멜 스펙트로그램을 PIL 이미지로 변환 시도\n","        try:\n","            mel_spec_image = ToPILImage()(mel_spec)\n","        except ValueError as e:\n","            # 에러 핸들링\n","            print(f\"Error converting mel spectrogram to image: {e}\")\n","            # 에러 발생 시 특정 처리 로직 (예: 기본 이미지 할당)\n","            mel_spec_image = None  # or some default handling\n","\n","        # 추가 변형이 있으면 적용\n","        if self.transform:\n","            mel_spec_image = self.transform(mel_spec_image)\n","\n","        label = self.y_data[idx]\n","        return mel_spec_image, label\n","\n","    def __len__(self):\n","        # 데이터셋 내 아이템의 총 개수 반환\n","        return len(self.X_data)\n","\n","# 멜스펙트로그램 데이터를 텐서로 변환\n","X_train_mel_tensor = torch.tensor(X_train_mel, dtype=torch.float32)\n","X_val_mel_tensor = torch.tensor(X_val_mel, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n","\n","# 입력 데이터의 차원 변환 및 채널 조정을 위한 전처리 파이프라인\n","# 데이터의 크기를 (224, 224)로 조정하고, 1채널을 3채널로 복제\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조정\n","    transforms.Grayscale(num_output_channels=3), # 1채널을 3채널로 변경\n","    transforms.ToTensor()\n","])\n","\n","# 데이터셋 생성\n","train_dataset = CustomMelSpectrogramDataset(X_train_mel_tensor, y_train_tensor, transform=transform)\n","val_dataset = CustomMelSpectrogramDataset(X_val_mel_tensor, y_val_tensor, transform=transform)\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# ResNet 모델 로드\n","model = models.resnet18(pretrained=True)  # ResNet18 모델을 로드\n","\n","# 마지막 FC 레이어를 사용자 정의 데이터셋에 맞게 변경\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 10)  # 클래스 개수를 맞추기 위해 10으로 설정\n","\n","# 손실 함수 및 옵티마이저 설정\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# GPU 사용 가능 여부 확인 후 모델을 GPU로 전송\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1714575704206,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"AW_Pc3rQrPnV","outputId":"6d0f25ac-e543-4185-9bdc-55f0ee2067fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["배치 인덱스: 0\n","데이터 형태: torch.Size([32, 3, 224, 224])\n","타겟 형태: torch.Size([32])\n"]}],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# DataLoader에서 첫 번째 배치의 형태를 출력합니다.\n","for batch_idx, (data, target) in enumerate(train_loader):\n","    print(f'배치 인덱스: {batch_idx}')\n","    print(f'데이터 형태: {data.shape}')  # 예: torch.Size([32, 10])\n","    print(f'타겟 형태: {target.shape}')  # 예: torch.Size([32])\n","    break  # 첫 번째 배치만 출력되도록 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"elapsed":723831,"status":"error","timestamp":1714583694580,"user":{"displayName":"김민정","userId":"02244240816509024948"},"user_tz":-540},"id":"NgJ-9AeOrP0E","outputId":"1e82f7c8-e937-492c-9742-bf67b52133ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Epoch 1] loss: 13.456\n","[Epoch 1] val_loss: 1.484, Accuracy: 96.25 %\n","[Epoch 2] loss: 1.031\n","[Epoch 2] val_loss: 0.304, Accuracy: 99.38 %\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-490680fb1117>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","\n","class EarlyStopping:\n","    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 종료\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Arguments:\n","            patience (int): 개선된 validation loss가 관찰되지 않는 epoch 횟수 후에 학습을 중단할 횟수\n","            verbose (bool): 조기 종료 메시지를 출력할지 결정\n","            delta (float): 개선으로 간주되기 위한 최소 변화량\n","            path (str): 모델 저장 경로\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_loss = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss > self.best_loss + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            if val_loss < self.best_loss:\n","                self.save_checkpoint(val_loss, model)\n","                self.best_loss = val_loss\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''validation loss가 감소하면 모델을 저장합니다.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss\n","\n","# EarlyStopping 객체 초기화\n","early_stopping = EarlyStopping(patience=20, verbose=True)\n","\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print('[Epoch %d] loss: %.3f' % (epoch + 1, running_loss))\n","\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_accuracy = 100 * correct / total\n","    print('[Epoch %d] val_loss: %.3f, Accuracy: %.2f %%' % (epoch + 1, val_loss, val_accuracy))\n","\n","    early_stopping(val_loss, model)\n","    if early_stopping.early_stop:\n","        print(\"조기 종료\")\n","        break"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOrzmnanVXyA2WdmP08tcyt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}