{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMADAKvYLsDtAwp6jo5QS58"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import warnings\n","import tensorflow as tf\n","from tqdm import tqdm\n","from glob import glob\n","from google.colab import drive\n","\n","import librosa\n","import librosa.display as dsp\n","import IPython.display as ipd\n","\n","warnings.filterwarnings(action='ignore')\n","drive.mount('/content/drive')\n","\n","%cd '/content/drive/MyDrive/deep-voice/data/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qw30Vm0vAQYe","executionInfo":{"status":"ok","timestamp":1714466256267,"user_tz":-540,"elapsed":18213,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"c4010251-9c10-450c-a86f-9ef8b235488a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/deep-voice/data\n"]}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') #GPU 할당"],"metadata":{"id":"kb9i7qDEAQqE","executionInfo":{"status":"ok","timestamp":1714466264703,"user_tz":-540,"elapsed":8447,"user":{"displayName":"김민정","userId":"02244240816509024948"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","seed_everything(813)"],"metadata":{"id":"vwbYsyOKAScP","executionInfo":{"status":"ok","timestamp":1714466264703,"user_tz":-540,"elapsed":19,"user":{"displayName":"김민정","userId":"02244240816509024948"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 저장된 데이터 불러오기\n","X_train_mel = np.load('X_train_mel.npy')\n","X_val_mel = np.load('X_val_mel.npy')\n","y_train = np.load('y_train.npy')\n","y_val = np.load('y_val.npy')"],"metadata":{"id":"VnJQgiuDAUPm","executionInfo":{"status":"ok","timestamp":1714466277749,"user_tz":-540,"elapsed":13064,"user":{"displayName":"김민정","userId":"02244240816509024948"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## VGG19"],"metadata":{"id":"8TMy0N-k1r99"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import models, optimizers, metrics\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dropout, Dense, Lambda, Reshape\n","from tensorflow.keras.applications.vgg19 import preprocess_input\n","\n","# 입력 차원을 (128, 2970, 1)에서 (128, 128, 3)으로 변경하는 사용자 정의 함수\n","def preprocess_image(x):\n","    # 1채널 grayscale 이미지를 3채널 RGB 이미지로 변환\n","    x = tf.image.grayscale_to_rgb(x)\n","    # 이미지 크기를 (128, 128)으로 조정\n","    x = tf.image.resize(x, [128, 128])\n","    return x\n","\n","input_shape = (128, 2970, 1)\n","\n","vgg19 = tf.keras.applications.vgg19.VGG19(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(128, 128, 3)  # input_shape를 (128, 128, 3)으로 변경\n",")\n","\n","# VGG19의 모든 계층을 동결합니다.\n","for layer in vgg19.layers:\n","    layer.trainable = False\n","\n","# Sequential 모델을 구성합니다.\n","model = Sequential([\n","    Lambda(preprocess_image, input_shape=input_shape),  # 입력 데이터 차원 및 채널 변경 및 크기 조정\n","    vgg19,\n","    Flatten(),\n","    Dropout(0.5),\n","    Dense(512, activation='relu'),\n","    Dense(2, activation='softmax')  # 최종 출력 계층입니다. 분류하고자 하는 클래스 수에 맞게 조정하세요.\n","])\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 요약 출력\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xcPIozZ8AkdS","executionInfo":{"status":"ok","timestamp":1714380006440,"user_tz":-540,"elapsed":1174,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"7198b05c-f740-454d-ad0e-8e1435e31ca1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lambda (Lambda)             (None, 128, 128, 3)       0         \n","                                                                 \n"," vgg19 (Functional)          (None, 4, 4, 512)         20024384  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               4194816   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 1026      \n","                                                                 \n","=================================================================\n","Total params: 24,220,226\n","Trainable params: 4,195,842\n","Non-trainable params: 20,024,384\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","# EarlyStopping 콜백 설정\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # 모니터링할 데이터\n","    patience=10,         # 성능 향상이 없는 에폭을 몇 번이나 허용할 것인가\n","    verbose=1,           # Early stopping의 진행 상황을 어떻게 표시할 것인지\n","    restore_best_weights=True  # 가장 좋은 모델의 가중치를 복원할지 여부\n",")\n","\n","# 모델 훈련\n","history = model.fit(\n","    X_train_mel, y_train,\n","    epochs=10,\n","    batch_size=32,\n","    validation_data=(X_val_mel, y_val),\n","    callbacks=[early_stopping]  # 콜백 리스트에 early_stopping 추가\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hf_oEcBuxcqh","outputId":"0b0fa95e-41c1-4815-d588-7f16c7401a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","40/40 [==============================] - 425s 11s/step - loss: 0.3121 - accuracy: 0.9742 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 2/10\n","40/40 [==============================] - 481s 12s/step - loss: 0.0146 - accuracy: 0.9992 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 3/10\n","40/40 [==============================] - 431s 11s/step - loss: 0.0332 - accuracy: 0.9992 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 4/10\n","40/40 [==============================] - 426s 11s/step - loss: 1.5775e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 5/10\n","40/40 [==============================] - 481s 12s/step - loss: 1.0910e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 6/10\n","38/40 [===========================>..] - ETA: 16s - loss: 3.9350e-05 - accuracy: 1.0000"]}]},{"cell_type":"markdown","source":["## GoogleNet"],"metadata":{"id":"DA-FWV0Z1upE"}},{"cell_type":"code","source":["import torch\n","from torchvision import transforms, models\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import ToPILImage\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","from torchvision.transforms import ToTensor\n","\n","class CustomMelSpectrogramDataset(Dataset):\n","    def __init__(self, X_data, y_data, transform=None):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        self.transform = transform\n","\n","    def __getitem__(self, idx):\n","        mel_spec = self.X_data[idx]\n","\n","        # 이미 데이터가 (Height, Width) 형태라고 가정할 때,\n","        # 여기서는 데이터가 torch.Tensor 형태임을 확인\n","        if not isinstance(mel_spec, torch.Tensor):\n","            raise ValueError(f\"Expected torch.Tensor, got {type(mel_spec)}.\")\n","\n","        # (높이, 너비, 채널)에서 (채널, 높이, 너비)로 차원 재배열\n","        mel_spec = mel_spec.permute(2, 0, 1)\n","\n","        # 멜 스펙트로그램을 PIL 이미지로 변환 시도\n","        try:\n","            mel_spec_image = ToPILImage()(mel_spec)\n","        except ValueError as e:\n","            # 에러 핸들링\n","            print(f\"Error converting mel spectrogram to image: {e}\")\n","            # 에러 발생 시 특정 처리 로직 (예: 기본 이미지 할당)\n","            mel_spec_image = None  # or some default handling\n","\n","        # 추가 변형이 있으면 적용\n","        if self.transform:\n","            mel_spec_image = self.transform(mel_spec_image)\n","\n","        label = self.y_data[idx]\n","        return mel_spec_image, label\n","\n","    def __len__(self):\n","        # 데이터셋 내 아이템의 총 개수 반환\n","        return len(self.X_data)\n","\n","# 멜스펙트로그램 데이터를 텐서로 변환\n","X_train_mel_tensor = torch.tensor(X_train_mel, dtype=torch.float32)\n","X_val_mel_tensor = torch.tensor(X_val_mel, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n","\n","# 입력 데이터의 차원 변환 및 채널 조정을 위한 전처리 파이프라인\n","# 데이터의 크기를 (224, 224)로 조정하고, 1채널을 3채널로 복제\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조정\n","    transforms.Grayscale(num_output_channels=3), # 1채널을 3채널로 변경\n","    transforms.ToTensor()\n","])\n","\n","# 데이터셋 생성\n","train_dataset = CustomMelSpectrogramDataset(X_train_mel_tensor, y_train_tensor, transform=transform)\n","val_dataset = CustomMelSpectrogramDataset(X_val_mel_tensor, y_val_tensor, transform=transform)\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# GoogLeNet 모델 로드\n","model = models.googlenet(pretrained=True)\n","\n","# 마지막 FC 레이어를 사용자 정의 데이터셋에 맞게 변경\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 10)\n","\n","# 손실 함수 및 옵티마이저 설정\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# GPU 사용 가능 여부 확인 후 모델을 GPU로 전송\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rv6E8Ftq1uMj","executionInfo":{"status":"ok","timestamp":1714466290538,"user_tz":-540,"elapsed":5356,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"bdba7d3f-4f94-4219-d420-4061e3d11a29"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GoogLeNet(\n","  (conv1): BasicConv2d(\n","    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (conv2): BasicConv2d(\n","    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (conv3): BasicConv2d(\n","    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception3a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception3b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception4a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4c): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4d): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4e): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception5a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception5b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (aux1): None\n","  (aux2): None\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# DataLoader에서 첫 번째 배치의 형태를 출력합니다.\n","for batch_idx, (data, target) in enumerate(train_loader):\n","    print(f'배치 인덱스: {batch_idx}')\n","    print(f'데이터 형태: {data.shape}')  # 예: torch.Size([32, 10])\n","    print(f'타겟 형태: {target.shape}')  # 예: torch.Size([32])\n","    break  # 첫 번째 배치만 출력되도록 합니다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9__4EYp44ezg","executionInfo":{"status":"ok","timestamp":1714466294404,"user_tz":-540,"elapsed":258,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"b618c27c-a336-44fb-95bc-5392bf7a5825"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["배치 인덱스: 0\n","데이터 형태: torch.Size([32, 3, 224, 224])\n","타겟 형태: torch.Size([32])\n"]}]},{"cell_type":"code","source":["# 훈련 과정\n","num_epochs = 25\n","for epoch in range(num_epochs):\n","    model.train()  # 학습 모드\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print('[Epoch %d] loss: %.3f' % (epoch + 1, running_loss))\n","\n","    # 검증 과정\n","    model.eval()  # 평가 모드\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print('[Epoch %d] val_loss: %.3f, Accuracy: %.2f %%' % (epoch + 1, val_loss, 100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"1BrgI0nS2kd-","executionInfo":{"status":"error","timestamp":1714468463173,"user_tz":-540,"elapsed":2165397,"user":{"displayName":"김민정","userId":"02244240816509024948"}},"outputId":"ac8e3446-bb5e-4878-eafe-e3d7c8d29525"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 1] loss: 29.340\n","[Epoch 1] val_loss: 3.508, Accuracy: 93.75 %\n","[Epoch 2] loss: 4.167\n","[Epoch 2] val_loss: 0.454, Accuracy: 99.69 %\n","[Epoch 3] loss: 2.158\n","[Epoch 3] val_loss: 0.278, Accuracy: 99.69 %\n","[Epoch 4] loss: 1.425\n","[Epoch 4] val_loss: 0.226, Accuracy: 99.69 %\n","[Epoch 5] loss: 1.152\n","[Epoch 5] val_loss: 0.159, Accuracy: 100.00 %\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-490680fb1117>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}